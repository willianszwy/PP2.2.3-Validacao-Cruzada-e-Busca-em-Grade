{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/willianszwy/PP2.2.3-Validacao-Cruzada-e-Busca-em-Grade/blob/main/PP2_2_3_Validac%CC%A7a%CC%83o_Cruzada_e_Busca_em_Grade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJtcr0Xkv6Fo"
   },
   "source": [
    "# Redes Neurais Artificiais 2021.1\n",
    "\n",
    "- **Disciplina**: Redes Neurais Artificiais 2021.1  \n",
    "- **Professora**: Elloá B. Guedes (ebgcosta@uea.edu.br)  \n",
    "- **Github**: http://github.com/elloa  \n",
    "        \n",
    "\n",
    "Levando em conta a base de dados **_Forest Cover Type_**, esta parte do Projeto Prático diz respeito à proposição e avaliação de múltiplas redes neurais artificiais do tipo feedforward multilayer perceptron para o problema da classificação multi-classe da cobertura florestal em uma área do Roosevelt National Forest.\n",
    "\n",
    "## Busca em Grade\n",
    "\n",
    "Uma maneira padrão de escolher os parâmetros de um modelo de Machine Learning é por meio de uma busca em grade via força bruta. O algoritmo da busca em grade é dado como segue:\n",
    "\n",
    "1. Escolha a métrica de desempenho que você deseja maximizar  \n",
    "2. Escolha o algoritmo de Machine Learning (exemplo: redes neurais artificiais). Em seguida, defina os parâmetros ou hiperparâmetros deste tipo de modelo sobre os quais você dseja otimizar (número de épocas, taxa de aprendizado, etc.) e construa um array de valores a serem testados para cada parâmetro ou hiperparâmetro.  \n",
    "3. Defina a grade de busca, a qual é dada como o produto cartesiano de cada parâmetro a ser testado. Por exemplo, para os arrays [50, 100, 1000] e [10, 15], tem-se que a grade é [(50,10), (50,15), (100,10), (100,15), (1000,10), (1000,15)].\n",
    "4. Para cada combinação de parâmetros a serem otimizados, utilize o conjunto de treinamento para realizar uma validação cruzada (holdout ou k-fold) e calcule a métrica de avaliação no conjunto de teste (ou conjuntos de teste)\n",
    "5. Escolha a combinação de parâmetros que maximizam a métrica de avaliação. Este é o modelo otimizado.\n",
    "\n",
    "Por que esta abordagem funciona? Porque a busca em grade efetua uma pesquisa extensiva sobre as possíveis combinações de valores para cada um dos parâmetros a serem ajustados. Para cada combinação, ela estima a performance do modelo em dados novos. Por fim, o modelo com melhor métrica de desempenho é escolhido. Tem-se então que este modelo é o que melhor pode vir a generalizar mediante dados nunca antes vistos.\n",
    "\n",
    "## Efetuando a Busca em Grade sobre Hiperparâmetros das Top-6 RNAs\n",
    "\n",
    "Considerando a etapa anterior do projeto prático, foram identificadas pelo menos 6 melhores Redes Neurais para o problema da classificação multi-classe da cobertura florestal no conjunto de dados selecionado. Algumas destas redes possuem atributos categóricos como variáveis preditoras, enquanto outras possuem apenas os atributos numéricos como preditores.\n",
    "\n",
    "A primeira etapa desta segunda parte do projeto consiste em trazer para este notebook estas seis arquiteturas, ressaltando:\n",
    "\n",
    "1. Número de neurônios ocultos por camada  \n",
    "2. Função de Ativação  \n",
    "3. Utilização ou não de atributos categóricos   \n",
    "4. Desempenho médio +- desvio padrão nos testes anteriores  \n",
    "5. Número de repetições que a equipe conseguiu realizar para verificar os resultados  \n",
    "\n",
    "Elabore uma busca em grade sobre estas arquiteturas que contemple variações nos hiperparâmetros a seguir, conforme documentação de [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "\n",
    "A. Solver  (Não usar o LBFGS, pois é mais adequado para datasets pequenos)  \n",
    "B. Batch Size  \n",
    "C. Learning Rate Init  \n",
    "D. Paciência (n_iter_no_change)  \n",
    "E. Épocas  \n",
    "\n",
    "Nesta busca em grande, contemple a utilização do objeto [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4pMGRAev6Fr"
   },
   "source": [
    "## Validação Cruzada k-fold\n",
    "\n",
    "Na elaboração da busca em grid, vamos avaliar os modelos propostos segundo uma estratégia de validação cruzada ainda não explorada até o momento: a validação cruzada k-fold. Segundo a mesma, o conjunto de dados é particionado em k partes: a cada iteração, separa-se uma das partes para teste e o modelo é treinado com as k-1 partes remanescentes. Valores sugestivos de k na literatura são k = 3, 5 ou 10, pois o custo computacional desta validação dos modelos é alto. A métrica de desempenho é resultante da média dos desempenhos nas k iterações. A figura a seguir ilustra a ideia desta avaliação\n",
    "\n",
    "<img src = \"https://ethen8181.github.io/machine-learning/model_selection/img/kfolds.png\" width=600></img>\n",
    "\n",
    "Considerando a métrica de desempenho F1-Score, considere a validação cruzada 5-fold para aferir os resultados da busca em grande anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8eKjuPLmv6Fr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4cTVt0kev6Fs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-18 15:33:10--  https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\n",
      "Resolvendo archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Conectando-se a archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... conectado.\n",
      "A requisição HTTP foi enviada, aguardando resposta... 200 OK\n",
      "Tamanho: 11240707 (11M) [application/x-httpd-php]\n",
      "Salvando em: “covtype.data.gz”\n",
      "\n",
      "covtype.data.gz     100%[===================>]  10,72M  3,52MB/s    em 3,0s    \n",
      "\n",
      "2021-12-18 15:33:14 (3,52 MB/s) - “covtype.data.gz” salvo [11240707/11240707]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4HmCDuOlv6Fs"
   },
   "outputs": [],
   "source": [
    "!gunzip covtype.data.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fJGCI0Ddv6Fs"
   },
   "outputs": [],
   "source": [
    "columns = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Cover_Type']\n",
    "df_forest_cover = pd.read_csv(\"covtype.data\", names = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forest_cover.drop(columns=['Wilderness_Area1',\n",
    "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
    "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
    "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
    "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
    "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
    "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
    "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
    "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
    "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
    "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
    "       'Soil_Type39', 'Soil_Type40'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 melhores arquiteturas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| activation | solver | hidden_layer_sizes | max_iter | atributos categóricos | acurácia média | acurácia desvio padrão | F1-Score média | F1-Score desvio padrão |\n",
    "|------------|--------|--------------------|----------|-----------------------|----------------|------------------------|----------------|------------------------|\n",
    "| 'tanh'     | 'adam' | (10, )            |      150 | não                   | 0.7223         | 0.0016                 | 0.4919         | 0.2633                 |\n",
    "| 'tanh'     | 'adam' | (10, )            |      200 | não                   | 0.7218         | 0.0025                 | 0.5072         | 0.2566                 |\n",
    "| 'relu'     | 'sgd'  | (10, )            |      300 | não                   | 0.7173         | 0.0005                 | 0.4763         | 0.2617                 |\n",
    "| 'relu'     | 'adam' | (10, )            |      300 | não                   | 0.7140         | 0.0007                 | 0.5064         | 0.2275                 |\n",
    "| 'tanh'     | 'adam' | (5, 5)             |      200 | não                   | 0.7097         | 0.0007                 | 0.4587         | 0.2665                 |\n",
    "| 'identity' | 'sgd'  | (15, )            |      200 | não                   | 0.6967         | 0.0005                 | 0.4198         | 0.2660                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BK1gBys0v6Ft"
   },
   "source": [
    "## Identificando a mellhor solução\n",
    "\n",
    "Como resultado da busca em grande com validação cruzada 5-fold, identifique o modelo otimizado com melhor desempenho para o problema. Apresente claramente este modelo, seus parâmetros, hiperparâmetros otimizados e resultados para cada um dos folds avaliados. Esta é a melhor solução identificada em decorrência deste projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Xv6BSs6Sv6Ft"
   },
   "outputs": [],
   "source": [
    "parameters = {'solver':['sgd','adam'],\n",
    "              'batch_size':[1,100],\n",
    "              'hidden_layer_sizes': [(10,),(5,5),(15)],\n",
    "              'learning_rate_init':[0.01,0.001],\n",
    "              'n_iter_no_change':[10],\n",
    "              'max_iter':[150,200],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LvPM8d6zv6Ft"
   },
   "outputs": [],
   "source": [
    "gridSearch = GridSearchCV(estimator = clf,          \n",
    "                    param_grid = parameters,\n",
    "                    n_jobs=-1,\n",
    "                    cv=5, verbose=10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_forest_cover['Cover_Type']\n",
    "X = df_forest_cover.drop('Cover_Type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = (X_train - np.mean(X_train))/np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = (X_test - np.mean(X_train))/np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 5/5; 4/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 4/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.660 total time=51.0min\n",
      "[CV 5/5; 8/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 8/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.705 total time=45.8min\n",
      "[CV 1/5; 12/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 12/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.689 total time=63.2min\n",
      "[CV 4/5; 16/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 16/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.709 total time=57.5min\n",
      "[CV 5/5; 20/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 20/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.688 total time=32.2min\n",
      "[CV 1/5; 24/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 24/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.723 total time=48.6min\n",
      "[CV 5/5; 40/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 40/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.710 total time= 2.6min\n",
      "[CV 1/5; 43/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 43/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.725 total time= 2.9min\n",
      "[CV 5/5; 46/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 46/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.725 total time= 3.5min\n",
      "[CV 1/5; 3/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 3/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.650 total time=26.4min\n",
      "[CV 3/5; 5/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 5/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.683 total time=38.5min\n",
      "[CV 1/5; 9/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 9/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.431 total time=55.1min\n",
      "[CV 3/5; 14/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 14/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.712 total time=65.0min\n",
      "[CV 2/5; 18/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 18/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.677 total time=35.2min\n",
      "[CV 3/5; 21/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 21/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.698 total time=65.3min\n",
      "[CV 1/5; 32/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 32/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.721 total time= 1.8min\n",
      "[CV 3/5; 33/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 33/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.706 total time= 2.4min\n",
      "[CV 4/5; 34/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 34/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.699 total time= 1.7min\n",
      "[CV 1/5; 36/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 36/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.698 total time= 1.5min\n",
      "[CV 1/5; 38/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 38/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.713 total time= 5.7min\n",
      "[CV 1/5; 41/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 41/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.727 total time= 3.1min\n",
      "[CV 1/5; 44/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 44/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.715 total time= 1.3min\n",
      "[CV 4/5; 45/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 45/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.723 total time= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 1/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.575 total time=28.4min\n",
      "[CV 4/5; 5/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 5/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.713 total time=48.8min\n",
      "[CV 1/5; 10/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 10/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.697 total time=42.1min\n",
      "[CV 4/5; 13/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 13/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.696 total time=97.8min\n",
      "[CV 4/5; 20/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 20/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.692 total time=37.0min\n",
      "[CV 2/5; 24/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 24/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.716 total time=36.3min\n",
      "[CV 2/5; 35/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 35/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.709 total time= 2.5min\n",
      "[CV 5/5; 37/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 37/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.700 total time= 5.1min\n",
      "[CV 4/5; 40/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 40/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.714 total time= 2.7min\n",
      "[CV 5/5; 42/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 42/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.721 total time= 1.2min\n",
      "[CV 3/5; 44/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 44/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.718 total time= 1.4min\n",
      "[CV 5/5; 45/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 45/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.718 total time= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 4/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.683 total time=30.9min\n",
      "[CV 3/5; 6/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 6/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.720 total time=58.1min\n",
      "[CV 5/5; 11/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 11/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.488 total time=30.9min\n",
      "[CV 2/5; 14/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 14/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.700 total time=48.0min\n",
      "[CV 1/5; 17/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 17/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.636 total time=27.5min\n",
      "[CV 1/5; 19/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 19/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.661 total time=29.7min\n",
      "[CV 1/5; 22/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 22/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.718 total time=40.7min\n",
      "[CV 2/5; 25/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 25/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.721 total time= 2.6min\n",
      "[CV 4/5; 25/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 25/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.719 total time= 3.2min\n",
      "[CV 3/5; 26/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 26/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.713 total time= 1.2min\n",
      "[CV 3/5; 27/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 27/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.716 total time= 1.4min\n",
      "[CV 5/5; 27/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 27/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.714 total time= 1.8min\n",
      "[CV 1/5; 29/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 29/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.714 total time= 3.7min\n",
      "[CV 1/5; 30/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 30/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.722 total time= 4.0min\n",
      "[CV 4/5; 31/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 31/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.716 total time= 3.6min\n",
      "[CV 2/5; 33/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 33/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.707 total time= 1.5min\n",
      "[CV 2/5; 34/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 34/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.699 total time= 1.4min\n",
      "[CV 5/5; 34/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 34/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.704 total time= 1.9min\n",
      "[CV 1/5; 37/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 37/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.706 total time= 5.1min\n",
      "[CV 4/5; 39/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 39/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.712 total time= 4.3min\n",
      "[CV 5/5; 43/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 43/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.723 total time= 2.7min\n",
      "[CV 1/5; 47/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 47/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.723 total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 4/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.660 total time=31.2min\n",
      "[CV 1/5; 7/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 7/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.714 total time=42.8min\n",
      "[CV 4/5; 9/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 9/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.488 total time=41.9min\n",
      "[CV 1/5; 13/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 13/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.703 total time=38.5min\n",
      "[CV 2/5; 16/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 16/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.706 total time=65.2min\n",
      "[CV 2/5; 21/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 21/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.712 total time=67.5min\n",
      "[CV 5/5; 32/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 32/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.718 total time= 4.4min\n",
      "[CV 2/5; 36/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 36/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.703 total time= 1.1min\n",
      "[CV 3/5; 37/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 37/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.710 total time= 2.6min\n",
      "[CV 5/5; 38/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 38/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.709 total time= 4.4min\n",
      "[CV 4/5; 41/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 41/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.727 total time= 2.5min\n",
      "[CV 4/5; 44/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 44/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.723 total time= 1.3min\n",
      "[CV 1/5; 46/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 46/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.728 total time= 4.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 2/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.688 total time=33.5min\n",
      "[CV 3/5; 7/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 7/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.711 total time=112.6min\n",
      "[CV 4/5; 15/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 15/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.704 total time=118.3min\n",
      "[CV 1/5; 25/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 25/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.719 total time= 1.9min\n",
      "[CV 3/5; 25/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 25/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.715 total time= 2.5min\n",
      "[CV 5/5; 25/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 25/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.714 total time= 1.3min\n",
      "[CV 2/5; 26/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 26/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.716 total time= 1.4min\n",
      "[CV 4/5; 26/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 26/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.719 total time=  43.9s\n",
      "[CV 1/5; 27/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 27/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.715 total time= 3.2min\n",
      "[CV 5/5; 28/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 28/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.706 total time= 1.2min\n",
      "[CV 4/5; 29/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 29/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.717 total time= 3.2min\n",
      "[CV 2/5; 30/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 30/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.714 total time= 1.9min\n",
      "[CV 1/5; 31/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 31/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.717 total time= 3.9min\n",
      "[CV 3/5; 32/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 32/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.712 total time= 2.1min\n",
      "[CV 4/5; 33/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 33/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.715 total time= 3.1min\n",
      "[CV 5/5; 35/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 35/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.707 total time= 1.5min\n",
      "[CV 4/5; 37/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 37/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.717 total time= 5.1min\n",
      "[CV 2/5; 40/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 40/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.704 total time= 3.1min\n",
      "[CV 2/5; 43/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 43/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.724 total time= 3.5min\n",
      "[CV 3/5; 47/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 47/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.725 total time= 4.1min\n",
      "[CV 1/5; 1/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 1/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.541 total time=39.4min\n",
      "[CV 2/5; 8/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 8/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.715 total time=36.8min\n",
      "[CV 5/5; 9/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 9/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.488 total time=31.7min\n",
      "[CV 3/5; 12/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 12/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.663 total time=51.9min\n",
      "[CV 3/5; 16/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 16/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.702 total time=67.3min\n",
      "[CV 2/5; 22/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 22/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.721 total time=33.9min\n",
      "[CV 3/5; 24/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 24/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.717 total time=39.4min\n",
      "[CV 1/5; 42/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 42/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.721 total time= 1.0min\n",
      "[CV 4/5; 43/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 43/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.723 total time= 2.9min\n",
      "[CV 2/5; 47/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 47/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.728 total time= 5.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 2/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.685 total time=31.0min\n",
      "[CV 4/5; 6/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 6/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.717 total time=38.8min\n",
      "[CV 3/5; 9/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 9/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.488 total time=49.7min\n",
      "[CV 1/5; 14/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 14/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.704 total time=69.3min\n",
      "[CV 5/5; 18/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 18/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.686 total time=32.6min\n",
      "[CV 5/5; 21/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 21/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.712 total time=88.0min\n",
      "[CV 4/5; 1/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 1/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.660 total time=28.5min\n",
      "[CV 5/5; 5/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 5/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.712 total time=69.9min\n",
      "[CV 2/5; 12/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 12/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.676 total time=39.3min\n",
      "[CV 3/5; 15/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 15/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.688 total time=38.4min\n",
      "[CV 4/5; 17/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 17/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.654 total time=27.4min\n",
      "[CV 2/5; 19/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 19/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.614 total time=31.8min\n",
      "[CV 4/5; 22/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 22/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.713 total time=37.4min\n",
      "[CV 2/5; 27/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 27/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.715 total time= 2.1min\n",
      "[CV 3/5; 28/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 28/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.708 total time= 2.2min\n",
      "[CV 5/5; 29/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 29/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.716 total time= 4.3min\n",
      "[CV 5/5; 30/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 30/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.719 total time= 3.6min\n",
      "[CV 5/5; 31/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 31/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.717 total time= 3.7min\n",
      "[CV 5/5; 33/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 33/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.705 total time= 2.0min\n",
      "[CV 4/5; 35/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 35/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.714 total time= 1.5min\n",
      "[CV 2/5; 37/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 37/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.713 total time= 5.1min\n",
      "[CV 1/5; 40/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 40/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.707 total time= 3.2min\n",
      "[CV 3/5; 42/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 42/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.720 total time= 1.7min\n",
      "[CV 5/5; 44/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 44/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.721 total time= 1.5min\n",
      "[CV 4/5; 46/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 46/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.729 total time= 3.1min\n",
      "[CV 3/5; 48/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 48/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.727 total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 2/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.693 total time=31.1min\n",
      "[CV 5/5; 6/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 6/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.712 total time=55.9min\n",
      "[CV 3/5; 11/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 11/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.365 total time=31.0min\n",
      "[CV 3/5; 13/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 13/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.688 total time=48.7min\n",
      "[CV 5/5; 16/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 16/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.705 total time=65.1min\n",
      "[CV 3/5; 22/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 22/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.723 total time=38.4min\n",
      "[CV 1/5; 26/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 26/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.710 total time= 1.9min\n",
      "[CV 5/5; 26/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 26/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.707 total time= 1.2min\n",
      "[CV 4/5; 27/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 27/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.721 total time= 1.3min\n",
      "[CV 1/5; 28/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 28/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.709 total time=  53.3s\n",
      "[CV 4/5; 28/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 28/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.713 total time= 1.1min\n",
      "[CV 2/5; 29/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 29/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.713 total time= 3.9min\n",
      "[CV 3/5; 30/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 30/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.715 total time= 1.8min\n",
      "[CV 2/5; 31/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 31/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.718 total time= 4.9min\n",
      "[CV 1/5; 33/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 33/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.716 total time= 3.5min\n",
      "[CV 3/5; 35/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 35/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.713 total time= 1.4min\n",
      "[CV 5/5; 36/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 36/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.706 total time= 1.8min\n",
      "[CV 2/5; 38/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 38/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.709 total time= 2.1min\n",
      "[CV 2/5; 39/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 39/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.710 total time= 4.6min\n",
      "[CV 2/5; 42/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 42/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.724 total time= 1.8min\n",
      "[CV 1/5; 45/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 45/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.725 total time= 4.5min\n",
      "[CV 2/5; 48/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 48/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.724 total time= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 4/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.680 total time=36.1min\n",
      "[CV 5/5; 7/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 7/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.667 total time=90.1min\n",
      "[CV 5/5; 14/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 14/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.706 total time=90.6min\n",
      "[CV 3/5; 20/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 20/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.679 total time=44.8min\n",
      "[CV 4/5; 24/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 24/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.719 total time=34.1min\n",
      "[CV 1/5; 39/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 39/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.709 total time= 5.0min\n",
      "[CV 4/5; 42/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 42/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.722 total time= 2.2min\n",
      "[CV 3/5; 45/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 45/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.726 total time= 4.3min\n",
      "[CV 5/5; 48/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 48/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.727 total time= 2.5min\n",
      "[CV 5/5; 3/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 3/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.674 total time=32.7min\n",
      "[CV 2/5; 7/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 7/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.707 total time=77.7min\n",
      "[CV 4/5; 12/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 12/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.699 total time=72.4min\n",
      "[CV 1/5; 18/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 18/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.679 total time=32.4min\n",
      "[CV 2/5; 20/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 20/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.687 total time=47.3min\n",
      "[CV 5/5; 24/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 24/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.714 total time=36.5min\n",
      "[CV 2/5; 41/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 41/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.726 total time= 2.4min\n",
      "[CV 3/5; 43/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 43/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.719 total time= 1.3min\n",
      "[CV 2/5; 45/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 45/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.723 total time= 4.5min\n",
      "[CV 4/5; 48/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 48/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.729 total time= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 2/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.688 total time=33.9min\n",
      "[CV 4/5; 7/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 7/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.711 total time=49.6min\n",
      "[CV 5/5; 10/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 10/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.666 total time=95.1min\n",
      "[CV 5/5; 17/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 17/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.661 total time=29.7min\n",
      "[CV 5/5; 19/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 19/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.628 total time=32.1min\n",
      "[CV 2/5; 23/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 23/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.717 total time=57.6min\n",
      "[CV 3/5; 40/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 40/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.716 total time= 7.7min\n",
      "[CV 4/5; 47/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 47/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.726 total time= 4.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 4/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.690 total time=48.7min\n",
      "[CV 4/5; 8/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 8/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.714 total time=39.1min\n",
      "[CV 4/5; 11/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 11/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.453 total time=41.8min\n",
      "[CV 2/5; 15/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 15/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.697 total time=88.1min\n",
      "[CV 1/5; 21/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 21/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.705 total time=57.0min\n",
      "[CV 2/5; 28/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 28/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.712 total time= 1.8min\n",
      "[CV 3/5; 29/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 29/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.719 total time= 4.3min\n",
      "[CV 4/5; 30/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 30/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.719 total time= 2.4min\n",
      "[CV 3/5; 31/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 31/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.714 total time= 2.4min\n",
      "[CV 2/5; 32/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 32/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.713 total time= 3.0min\n",
      "[CV 1/5; 34/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 34/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.706 total time= 1.5min\n",
      "[CV 1/5; 35/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 35/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.709 total time= 1.7min\n",
      "[CV 4/5; 36/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 36/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.707 total time= 2.0min\n",
      "[CV 3/5; 38/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 38/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.703 total time= 3.3min\n",
      "[CV 5/5; 39/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 39/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.698 total time= 2.7min\n",
      "[CV 5/5; 41/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 41/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.723 total time= 2.0min\n",
      "[CV 2/5; 44/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 44/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.722 total time= 1.7min\n",
      "[CV 3/5; 46/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 46/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.729 total time= 3.1min\n",
      "[CV 1/5; 48/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 48/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.729 total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 3/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.680 total time=39.2min\n",
      "[CV 1/5; 8/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 8/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.714 total time=44.1min\n",
      "[CV 4/5; 10/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 10/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.674 total time=39.5min\n",
      "[CV 4/5; 14/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 14/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.709 total time=51.2min\n",
      "[CV 3/5; 17/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 17/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.633 total time=63.8min\n",
      "[CV 5/5; 22/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 22/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.718 total time=48.7min\n",
      "[CV 4/5; 32/48] START batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 32/48] END batch_size=100, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.720 total time= 3.1min\n",
      "[CV 3/5; 34/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 34/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.714 total time= 2.2min\n",
      "[CV 3/5; 36/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 36/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.706 total time= 2.1min\n",
      "[CV 4/5; 38/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 38/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.713 total time= 2.8min\n",
      "[CV 3/5; 39/48] START batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 39/48] END batch_size=100, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.697 total time= 2.8min\n",
      "[CV 3/5; 41/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 41/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.730 total time= 4.0min\n",
      "[CV 2/5; 46/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 46/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.727 total time= 3.0min\n",
      "[CV 5/5; 47/48] START batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 47/48] END batch_size=100, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.718 total time= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willians/opt/anaconda3/envs/visao_computacional/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 2/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.684 total time=43.5min\n",
      "[CV 3/5; 8/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 8/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.713 total time=33.9min\n",
      "[CV 2/5; 10/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 10/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.686 total time=76.0min\n",
      "[CV 5/5; 15/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 15/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.698 total time=51.5min\n",
      "[CV 3/5; 19/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 19/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.633 total time=40.2min\n",
      "[CV 4/5; 23/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 23/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.721 total time=65.9min\n",
      "[CV 5/5; 1/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 1/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.578 total time=26.3min\n",
      "[CV 2/5; 5/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 5/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.691 total time=57.5min\n",
      "[CV 1/5; 11/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 11/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.488 total time=31.1min\n",
      "[CV 5/5; 12/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 5/5; 12/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.681 total time=38.9min\n",
      "[CV 1/5; 16/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 16/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.706 total time=60.5min\n",
      "[CV 1/5; 20/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 20/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=adam;, score=0.681 total time=34.8min\n",
      "[CV 5/5; 23/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 23/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.708 total time=61.8min\n",
      "[CV 2/5; 3/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 3/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.620 total time=30.6min\n",
      "[CV 2/5; 6/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 2/5; 6/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.712 total time=38.9min\n",
      "[CV 2/5; 9/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 9/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.426 total time=49.9min\n",
      "[CV 5/5; 13/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 5/5; 13/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.688 total time=66.9min\n",
      "[CV 3/5; 18/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 18/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.681 total time=52.4min\n",
      "[CV 1/5; 23/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 23/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.716 total time=75.7min\n",
      "[CV 3/5; 3/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 3/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.540 total time=26.2min\n",
      "[CV 1/5; 5/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 5/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.692 total time=59.5min\n",
      "[CV 2/5; 11/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 11/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.488 total time=30.9min\n",
      "[CV 2/5; 13/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 13/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.695 total time=53.7min\n",
      "[CV 2/5; 17/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 2/5; 17/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.604 total time=37.8min\n",
      "[CV 4/5; 19/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 19/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.629 total time=33.8min\n",
      "[CV 3/5; 23/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 23/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.716 total time=82.7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(), n_jobs=-1,\n",
       "             param_grid={'batch_size': [1, 100],\n",
       "                         'hidden_layer_sizes': [(10,), (5, 5), 15],\n",
       "                         'learning_rate_init': [0.01, 0.001],\n",
       "                         'max_iter': [150, 200], 'n_iter_no_change': [10],\n",
       "                         'solver': ['sgd', 'adam']},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_n_iter_no_change</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1834.067088</td>\n",
       "      <td>275.943466</td>\n",
       "      <td>0.044498</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (10,),...</td>\n",
       "      <td>0.540533</td>\n",
       "      <td>0.575164</td>\n",
       "      <td>0.644845</td>\n",
       "      <td>0.660319</td>\n",
       "      <td>0.577937</td>\n",
       "      <td>0.599760</td>\n",
       "      <td>0.045363</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2074.820235</td>\n",
       "      <td>275.655450</td>\n",
       "      <td>0.054162</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (10,),...</td>\n",
       "      <td>0.693209</td>\n",
       "      <td>0.688095</td>\n",
       "      <td>0.688095</td>\n",
       "      <td>0.684132</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.687643</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1860.554830</td>\n",
       "      <td>287.481471</td>\n",
       "      <td>0.045469</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (10,),...</td>\n",
       "      <td>0.649935</td>\n",
       "      <td>0.620467</td>\n",
       "      <td>0.540348</td>\n",
       "      <td>0.680432</td>\n",
       "      <td>0.674162</td>\n",
       "      <td>0.633069</td>\n",
       "      <td>0.050936</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2374.595786</td>\n",
       "      <td>516.966598</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (10,),...</td>\n",
       "      <td>0.683177</td>\n",
       "      <td>0.680337</td>\n",
       "      <td>0.689742</td>\n",
       "      <td>0.659864</td>\n",
       "      <td>0.660048</td>\n",
       "      <td>0.674634</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3290.941878</td>\n",
       "      <td>632.933984</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (10,),...</td>\n",
       "      <td>0.692484</td>\n",
       "      <td>0.691340</td>\n",
       "      <td>0.682722</td>\n",
       "      <td>0.712666</td>\n",
       "      <td>0.711818</td>\n",
       "      <td>0.698206</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2933.899747</td>\n",
       "      <td>502.467258</td>\n",
       "      <td>0.041928</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (10,),...</td>\n",
       "      <td>0.715743</td>\n",
       "      <td>0.711514</td>\n",
       "      <td>0.720231</td>\n",
       "      <td>0.716994</td>\n",
       "      <td>0.712433</td>\n",
       "      <td>0.715383</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4472.737686</td>\n",
       "      <td>1549.490562</td>\n",
       "      <td>0.043365</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (10,),...</td>\n",
       "      <td>0.714096</td>\n",
       "      <td>0.707334</td>\n",
       "      <td>0.711293</td>\n",
       "      <td>0.711388</td>\n",
       "      <td>0.667154</td>\n",
       "      <td>0.702253</td>\n",
       "      <td>0.017681</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2395.877275</td>\n",
       "      <td>265.702565</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (10,),...</td>\n",
       "      <td>0.713838</td>\n",
       "      <td>0.715215</td>\n",
       "      <td>0.713432</td>\n",
       "      <td>0.714179</td>\n",
       "      <td>0.705167</td>\n",
       "      <td>0.712366</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2739.628466</td>\n",
       "      <td>489.997089</td>\n",
       "      <td>0.037651</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>1</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (5, 5)...</td>\n",
       "      <td>0.430921</td>\n",
       "      <td>0.426213</td>\n",
       "      <td>0.487682</td>\n",
       "      <td>0.487688</td>\n",
       "      <td>0.487688</td>\n",
       "      <td>0.464038</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3564.465150</td>\n",
       "      <td>1333.273646</td>\n",
       "      <td>0.042708</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>1</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (5, 5)...</td>\n",
       "      <td>0.697229</td>\n",
       "      <td>0.686214</td>\n",
       "      <td>0.686706</td>\n",
       "      <td>0.673830</td>\n",
       "      <td>0.665753</td>\n",
       "      <td>0.681946</td>\n",
       "      <td>0.010977</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1988.214960</td>\n",
       "      <td>259.392604</td>\n",
       "      <td>0.037593</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>1</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (5, 5)...</td>\n",
       "      <td>0.487694</td>\n",
       "      <td>0.487682</td>\n",
       "      <td>0.364621</td>\n",
       "      <td>0.453449</td>\n",
       "      <td>0.487688</td>\n",
       "      <td>0.456227</td>\n",
       "      <td>0.047684</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3188.445294</td>\n",
       "      <td>790.771812</td>\n",
       "      <td>0.043958</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>1</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (5, 5)...</td>\n",
       "      <td>0.688709</td>\n",
       "      <td>0.675850</td>\n",
       "      <td>0.663433</td>\n",
       "      <td>0.699389</td>\n",
       "      <td>0.680567</td>\n",
       "      <td>0.681590</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3666.475302</td>\n",
       "      <td>1228.699635</td>\n",
       "      <td>0.039547</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>1</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (5, 5)...</td>\n",
       "      <td>0.702700</td>\n",
       "      <td>0.695483</td>\n",
       "      <td>0.688205</td>\n",
       "      <td>0.696143</td>\n",
       "      <td>0.687857</td>\n",
       "      <td>0.694078</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3888.526180</td>\n",
       "      <td>911.378848</td>\n",
       "      <td>0.049033</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>1</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (5, 5)...</td>\n",
       "      <td>0.704089</td>\n",
       "      <td>0.700278</td>\n",
       "      <td>0.711662</td>\n",
       "      <td>0.709445</td>\n",
       "      <td>0.706249</td>\n",
       "      <td>0.706345</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4288.806610</td>\n",
       "      <td>1712.795569</td>\n",
       "      <td>0.041103</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>1</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (5, 5)...</td>\n",
       "      <td>0.671646</td>\n",
       "      <td>0.696516</td>\n",
       "      <td>0.688341</td>\n",
       "      <td>0.704159</td>\n",
       "      <td>0.698246</td>\n",
       "      <td>0.691781</td>\n",
       "      <td>0.011267</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3788.390313</td>\n",
       "      <td>215.052532</td>\n",
       "      <td>0.045829</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>1</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': (5, 5)...</td>\n",
       "      <td>0.705663</td>\n",
       "      <td>0.706265</td>\n",
       "      <td>0.702392</td>\n",
       "      <td>0.709372</td>\n",
       "      <td>0.704651</td>\n",
       "      <td>0.705668</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2233.102294</td>\n",
       "      <td>828.491797</td>\n",
       "      <td>0.041690</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': 15, 'l...</td>\n",
       "      <td>0.636080</td>\n",
       "      <td>0.603956</td>\n",
       "      <td>0.633252</td>\n",
       "      <td>0.653975</td>\n",
       "      <td>0.661462</td>\n",
       "      <td>0.637745</td>\n",
       "      <td>0.019953</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2217.031783</td>\n",
       "      <td>467.474346</td>\n",
       "      <td>0.056544</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': 15, 'l...</td>\n",
       "      <td>0.678973</td>\n",
       "      <td>0.676612</td>\n",
       "      <td>0.680509</td>\n",
       "      <td>0.693844</td>\n",
       "      <td>0.685866</td>\n",
       "      <td>0.683161</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2012.701641</td>\n",
       "      <td>215.189174</td>\n",
       "      <td>0.040206</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': 15, 'l...</td>\n",
       "      <td>0.660680</td>\n",
       "      <td>0.614197</td>\n",
       "      <td>0.632920</td>\n",
       "      <td>0.629498</td>\n",
       "      <td>0.627580</td>\n",
       "      <td>0.632975</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2353.783807</td>\n",
       "      <td>349.732746</td>\n",
       "      <td>0.057159</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': 15, 'l...</td>\n",
       "      <td>0.680915</td>\n",
       "      <td>0.687173</td>\n",
       "      <td>0.679428</td>\n",
       "      <td>0.692160</td>\n",
       "      <td>0.688349</td>\n",
       "      <td>0.685605</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4686.947223</td>\n",
       "      <td>1205.626077</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': 15, 'l...</td>\n",
       "      <td>0.705085</td>\n",
       "      <td>0.712178</td>\n",
       "      <td>0.698102</td>\n",
       "      <td>0.725772</td>\n",
       "      <td>0.712113</td>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2390.770436</td>\n",
       "      <td>297.348258</td>\n",
       "      <td>0.043638</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': 15, 'l...</td>\n",
       "      <td>0.718362</td>\n",
       "      <td>0.720907</td>\n",
       "      <td>0.723009</td>\n",
       "      <td>0.713023</td>\n",
       "      <td>0.717867</td>\n",
       "      <td>0.718634</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4123.729835</td>\n",
       "      <td>552.789263</td>\n",
       "      <td>0.025659</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': 15, 'l...</td>\n",
       "      <td>0.715768</td>\n",
       "      <td>0.716715</td>\n",
       "      <td>0.715522</td>\n",
       "      <td>0.721371</td>\n",
       "      <td>0.708241</td>\n",
       "      <td>0.715523</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2338.356912</td>\n",
       "      <td>306.452949</td>\n",
       "      <td>0.040906</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 1, 'hidden_layer_sizes': 15, 'l...</td>\n",
       "      <td>0.723402</td>\n",
       "      <td>0.715522</td>\n",
       "      <td>0.716948</td>\n",
       "      <td>0.718949</td>\n",
       "      <td>0.714129</td>\n",
       "      <td>0.717790</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>140.376769</td>\n",
       "      <td>38.719498</td>\n",
       "      <td>0.039631</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>100</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (10,...</td>\n",
       "      <td>0.718608</td>\n",
       "      <td>0.721251</td>\n",
       "      <td>0.714612</td>\n",
       "      <td>0.718764</td>\n",
       "      <td>0.714191</td>\n",
       "      <td>0.717485</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>77.060044</td>\n",
       "      <td>22.577055</td>\n",
       "      <td>0.045545</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>100</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (10,...</td>\n",
       "      <td>0.710396</td>\n",
       "      <td>0.715731</td>\n",
       "      <td>0.713371</td>\n",
       "      <td>0.719317</td>\n",
       "      <td>0.707405</td>\n",
       "      <td>0.713244</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>117.306429</td>\n",
       "      <td>42.350406</td>\n",
       "      <td>0.038714</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>100</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (10,...</td>\n",
       "      <td>0.714760</td>\n",
       "      <td>0.715498</td>\n",
       "      <td>0.716223</td>\n",
       "      <td>0.721174</td>\n",
       "      <td>0.714277</td>\n",
       "      <td>0.716386</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>86.165348</td>\n",
       "      <td>29.118015</td>\n",
       "      <td>0.038709</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>100</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (10,...</td>\n",
       "      <td>0.709412</td>\n",
       "      <td>0.711723</td>\n",
       "      <td>0.707802</td>\n",
       "      <td>0.713207</td>\n",
       "      <td>0.706101</td>\n",
       "      <td>0.709649</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>234.262950</td>\n",
       "      <td>25.370711</td>\n",
       "      <td>0.039169</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>100</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (10,...</td>\n",
       "      <td>0.714022</td>\n",
       "      <td>0.712817</td>\n",
       "      <td>0.719456</td>\n",
       "      <td>0.716896</td>\n",
       "      <td>0.715728</td>\n",
       "      <td>0.715784</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>165.830937</td>\n",
       "      <td>53.342979</td>\n",
       "      <td>0.038379</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>100</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (10,...</td>\n",
       "      <td>0.722001</td>\n",
       "      <td>0.714010</td>\n",
       "      <td>0.714883</td>\n",
       "      <td>0.719195</td>\n",
       "      <td>0.718518</td>\n",
       "      <td>0.717721</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>221.583837</td>\n",
       "      <td>48.896178</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>0.006964</td>\n",
       "      <td>100</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (10,...</td>\n",
       "      <td>0.716936</td>\n",
       "      <td>0.718116</td>\n",
       "      <td>0.714280</td>\n",
       "      <td>0.716490</td>\n",
       "      <td>0.716908</td>\n",
       "      <td>0.716546</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>174.685827</td>\n",
       "      <td>54.690139</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>100</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (10,...</td>\n",
       "      <td>0.721399</td>\n",
       "      <td>0.713223</td>\n",
       "      <td>0.712227</td>\n",
       "      <td>0.720448</td>\n",
       "      <td>0.718334</td>\n",
       "      <td>0.717126</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>149.171343</td>\n",
       "      <td>42.872388</td>\n",
       "      <td>0.040389</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>100</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (5, ...</td>\n",
       "      <td>0.716309</td>\n",
       "      <td>0.706732</td>\n",
       "      <td>0.706326</td>\n",
       "      <td>0.714609</td>\n",
       "      <td>0.705364</td>\n",
       "      <td>0.709868</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>102.878479</td>\n",
       "      <td>17.053121</td>\n",
       "      <td>0.046267</td>\n",
       "      <td>0.011368</td>\n",
       "      <td>100</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (5, ...</td>\n",
       "      <td>0.706105</td>\n",
       "      <td>0.699491</td>\n",
       "      <td>0.714022</td>\n",
       "      <td>0.698860</td>\n",
       "      <td>0.704196</td>\n",
       "      <td>0.704535</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>103.216205</td>\n",
       "      <td>23.782001</td>\n",
       "      <td>0.040033</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>100</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (5, ...</td>\n",
       "      <td>0.709166</td>\n",
       "      <td>0.708957</td>\n",
       "      <td>0.712904</td>\n",
       "      <td>0.714486</td>\n",
       "      <td>0.706778</td>\n",
       "      <td>0.710458</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>102.852523</td>\n",
       "      <td>21.712468</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>100</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (5, ...</td>\n",
       "      <td>0.698323</td>\n",
       "      <td>0.703364</td>\n",
       "      <td>0.706289</td>\n",
       "      <td>0.707036</td>\n",
       "      <td>0.705856</td>\n",
       "      <td>0.704174</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>278.266927</td>\n",
       "      <td>59.698071</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>100</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (5, ...</td>\n",
       "      <td>0.705749</td>\n",
       "      <td>0.712830</td>\n",
       "      <td>0.710432</td>\n",
       "      <td>0.716687</td>\n",
       "      <td>0.700102</td>\n",
       "      <td>0.709160</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>219.324113</td>\n",
       "      <td>76.253835</td>\n",
       "      <td>0.042467</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>100</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (5, ...</td>\n",
       "      <td>0.713014</td>\n",
       "      <td>0.709043</td>\n",
       "      <td>0.702909</td>\n",
       "      <td>0.712519</td>\n",
       "      <td>0.709064</td>\n",
       "      <td>0.709310</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>232.079107</td>\n",
       "      <td>57.399620</td>\n",
       "      <td>0.039831</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>100</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (5, ...</td>\n",
       "      <td>0.708748</td>\n",
       "      <td>0.710174</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.712212</td>\n",
       "      <td>0.697729</td>\n",
       "      <td>0.705194</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>232.678880</td>\n",
       "      <td>116.329471</td>\n",
       "      <td>0.044868</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>100</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': (5, ...</td>\n",
       "      <td>0.707285</td>\n",
       "      <td>0.703966</td>\n",
       "      <td>0.715633</td>\n",
       "      <td>0.714289</td>\n",
       "      <td>0.709728</td>\n",
       "      <td>0.710180</td>\n",
       "      <td>0.004332</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>167.480826</td>\n",
       "      <td>42.948477</td>\n",
       "      <td>0.042542</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': 15, ...</td>\n",
       "      <td>0.726587</td>\n",
       "      <td>0.725615</td>\n",
       "      <td>0.729574</td>\n",
       "      <td>0.726792</td>\n",
       "      <td>0.722674</td>\n",
       "      <td>0.726248</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>96.123919</td>\n",
       "      <td>25.481638</td>\n",
       "      <td>0.043030</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': 15, ...</td>\n",
       "      <td>0.720735</td>\n",
       "      <td>0.724411</td>\n",
       "      <td>0.719628</td>\n",
       "      <td>0.721629</td>\n",
       "      <td>0.721137</td>\n",
       "      <td>0.721508</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>160.317668</td>\n",
       "      <td>43.296669</td>\n",
       "      <td>0.041960</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': 15, ...</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.724226</td>\n",
       "      <td>0.718596</td>\n",
       "      <td>0.722649</td>\n",
       "      <td>0.722723</td>\n",
       "      <td>0.722587</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>86.862273</td>\n",
       "      <td>7.477811</td>\n",
       "      <td>0.041462</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': 15, ...</td>\n",
       "      <td>0.715055</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.717932</td>\n",
       "      <td>0.723325</td>\n",
       "      <td>0.720891</td>\n",
       "      <td>0.719772</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>268.863267</td>\n",
       "      <td>4.103896</td>\n",
       "      <td>0.039585</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': 15, ...</td>\n",
       "      <td>0.724841</td>\n",
       "      <td>0.722739</td>\n",
       "      <td>0.725800</td>\n",
       "      <td>0.723079</td>\n",
       "      <td>0.718063</td>\n",
       "      <td>0.722904</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>211.156065</td>\n",
       "      <td>42.122830</td>\n",
       "      <td>0.041963</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': 15, ...</td>\n",
       "      <td>0.728283</td>\n",
       "      <td>0.726599</td>\n",
       "      <td>0.729217</td>\n",
       "      <td>0.728710</td>\n",
       "      <td>0.724592</td>\n",
       "      <td>0.727480</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>265.647352</td>\n",
       "      <td>29.807800</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': 15, ...</td>\n",
       "      <td>0.723157</td>\n",
       "      <td>0.727582</td>\n",
       "      <td>0.724792</td>\n",
       "      <td>0.725846</td>\n",
       "      <td>0.718027</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>181.424673</td>\n",
       "      <td>35.309018</td>\n",
       "      <td>0.030776</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'batch_size': 100, 'hidden_layer_sizes': 15, ...</td>\n",
       "      <td>0.728504</td>\n",
       "      <td>0.723845</td>\n",
       "      <td>0.726648</td>\n",
       "      <td>0.729153</td>\n",
       "      <td>0.727063</td>\n",
       "      <td>0.727043</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     1834.067088    275.943466         0.044498        0.001062   \n",
       "1     2074.820235    275.655450         0.054162        0.004743   \n",
       "2     1860.554830    287.481471         0.045469        0.001720   \n",
       "3     2374.595786    516.966598         0.056015        0.005332   \n",
       "4     3290.941878    632.933984         0.043980        0.002620   \n",
       "5     2933.899747    502.467258         0.041928        0.003198   \n",
       "6     4472.737686   1549.490562         0.043365        0.002052   \n",
       "7     2395.877275    265.702565         0.043831        0.004000   \n",
       "8     2739.628466    489.997089         0.037651        0.001860   \n",
       "9     3564.465150   1333.273646         0.042708        0.002981   \n",
       "10    1988.214960    259.392604         0.037593        0.002360   \n",
       "11    3188.445294    790.771812         0.043958        0.002911   \n",
       "12    3666.475302   1228.699635         0.039547        0.001968   \n",
       "13    3888.526180    911.378848         0.049033        0.008808   \n",
       "14    4288.806610   1712.795569         0.041103        0.001849   \n",
       "15    3788.390313    215.052532         0.045829        0.004244   \n",
       "16    2233.102294    828.491797         0.041690        0.002216   \n",
       "17    2217.031783    467.474346         0.056544        0.007467   \n",
       "18    2012.701641    215.189174         0.040206        0.000483   \n",
       "19    2353.783807    349.732746         0.057159        0.004231   \n",
       "20    4686.947223   1205.626077         0.033536        0.010101   \n",
       "21    2390.770436    297.348258         0.043638        0.004761   \n",
       "22    4123.729835    552.789263         0.025659        0.008115   \n",
       "23    2338.356912    306.452949         0.040906        0.001786   \n",
       "24     140.376769     38.719498         0.039631        0.002738   \n",
       "25      77.060044     22.577055         0.045545        0.003333   \n",
       "26     117.306429     42.350406         0.038714        0.000875   \n",
       "27      86.165348     29.118015         0.038709        0.000829   \n",
       "28     234.262950     25.370711         0.039169        0.002531   \n",
       "29     165.830937     53.342979         0.038379        0.001214   \n",
       "30     221.583837     48.896178         0.042732        0.006964   \n",
       "31     174.685827     54.690139         0.040844        0.000944   \n",
       "32     149.171343     42.872388         0.040389        0.001608   \n",
       "33     102.878479     17.053121         0.046267        0.011368   \n",
       "34     103.216205     23.782001         0.040033        0.001547   \n",
       "35     102.852523     21.712468         0.046100        0.009331   \n",
       "36     278.266927     59.698071         0.042339        0.003370   \n",
       "37     219.324113     76.253835         0.042467        0.003565   \n",
       "38     232.079107     57.399620         0.039831        0.001331   \n",
       "39     232.678880    116.329471         0.044868        0.008362   \n",
       "40     167.480826     42.948477         0.042542        0.001994   \n",
       "41      96.123919     25.481638         0.043030        0.002843   \n",
       "42     160.317668     43.296669         0.041960        0.000913   \n",
       "43      86.862273      7.477811         0.041462        0.001273   \n",
       "44     268.863267      4.103896         0.039585        0.002390   \n",
       "45     211.156065     42.122830         0.041963        0.002007   \n",
       "46     265.647352     29.807800         0.032912        0.006575   \n",
       "47     181.424673     35.309018         0.030776        0.004730   \n",
       "\n",
       "   param_batch_size param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "0                 1                    (10,)                     0.01   \n",
       "1                 1                    (10,)                     0.01   \n",
       "2                 1                    (10,)                     0.01   \n",
       "3                 1                    (10,)                     0.01   \n",
       "4                 1                    (10,)                    0.001   \n",
       "5                 1                    (10,)                    0.001   \n",
       "6                 1                    (10,)                    0.001   \n",
       "7                 1                    (10,)                    0.001   \n",
       "8                 1                   (5, 5)                     0.01   \n",
       "9                 1                   (5, 5)                     0.01   \n",
       "10                1                   (5, 5)                     0.01   \n",
       "11                1                   (5, 5)                     0.01   \n",
       "12                1                   (5, 5)                    0.001   \n",
       "13                1                   (5, 5)                    0.001   \n",
       "14                1                   (5, 5)                    0.001   \n",
       "15                1                   (5, 5)                    0.001   \n",
       "16                1                       15                     0.01   \n",
       "17                1                       15                     0.01   \n",
       "18                1                       15                     0.01   \n",
       "19                1                       15                     0.01   \n",
       "20                1                       15                    0.001   \n",
       "21                1                       15                    0.001   \n",
       "22                1                       15                    0.001   \n",
       "23                1                       15                    0.001   \n",
       "24              100                    (10,)                     0.01   \n",
       "25              100                    (10,)                     0.01   \n",
       "26              100                    (10,)                     0.01   \n",
       "27              100                    (10,)                     0.01   \n",
       "28              100                    (10,)                    0.001   \n",
       "29              100                    (10,)                    0.001   \n",
       "30              100                    (10,)                    0.001   \n",
       "31              100                    (10,)                    0.001   \n",
       "32              100                   (5, 5)                     0.01   \n",
       "33              100                   (5, 5)                     0.01   \n",
       "34              100                   (5, 5)                     0.01   \n",
       "35              100                   (5, 5)                     0.01   \n",
       "36              100                   (5, 5)                    0.001   \n",
       "37              100                   (5, 5)                    0.001   \n",
       "38              100                   (5, 5)                    0.001   \n",
       "39              100                   (5, 5)                    0.001   \n",
       "40              100                       15                     0.01   \n",
       "41              100                       15                     0.01   \n",
       "42              100                       15                     0.01   \n",
       "43              100                       15                     0.01   \n",
       "44              100                       15                    0.001   \n",
       "45              100                       15                    0.001   \n",
       "46              100                       15                    0.001   \n",
       "47              100                       15                    0.001   \n",
       "\n",
       "   param_max_iter param_n_iter_no_change param_solver  \\\n",
       "0             150                     10          sgd   \n",
       "1             150                     10         adam   \n",
       "2             200                     10          sgd   \n",
       "3             200                     10         adam   \n",
       "4             150                     10          sgd   \n",
       "5             150                     10         adam   \n",
       "6             200                     10          sgd   \n",
       "7             200                     10         adam   \n",
       "8             150                     10          sgd   \n",
       "9             150                     10         adam   \n",
       "10            200                     10          sgd   \n",
       "11            200                     10         adam   \n",
       "12            150                     10          sgd   \n",
       "13            150                     10         adam   \n",
       "14            200                     10          sgd   \n",
       "15            200                     10         adam   \n",
       "16            150                     10          sgd   \n",
       "17            150                     10         adam   \n",
       "18            200                     10          sgd   \n",
       "19            200                     10         adam   \n",
       "20            150                     10          sgd   \n",
       "21            150                     10         adam   \n",
       "22            200                     10          sgd   \n",
       "23            200                     10         adam   \n",
       "24            150                     10          sgd   \n",
       "25            150                     10         adam   \n",
       "26            200                     10          sgd   \n",
       "27            200                     10         adam   \n",
       "28            150                     10          sgd   \n",
       "29            150                     10         adam   \n",
       "30            200                     10          sgd   \n",
       "31            200                     10         adam   \n",
       "32            150                     10          sgd   \n",
       "33            150                     10         adam   \n",
       "34            200                     10          sgd   \n",
       "35            200                     10         adam   \n",
       "36            150                     10          sgd   \n",
       "37            150                     10         adam   \n",
       "38            200                     10          sgd   \n",
       "39            200                     10         adam   \n",
       "40            150                     10          sgd   \n",
       "41            150                     10         adam   \n",
       "42            200                     10          sgd   \n",
       "43            200                     10         adam   \n",
       "44            150                     10          sgd   \n",
       "45            150                     10         adam   \n",
       "46            200                     10          sgd   \n",
       "47            200                     10         adam   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'batch_size': 1, 'hidden_layer_sizes': (10,),...           0.540533   \n",
       "1   {'batch_size': 1, 'hidden_layer_sizes': (10,),...           0.693209   \n",
       "2   {'batch_size': 1, 'hidden_layer_sizes': (10,),...           0.649935   \n",
       "3   {'batch_size': 1, 'hidden_layer_sizes': (10,),...           0.683177   \n",
       "4   {'batch_size': 1, 'hidden_layer_sizes': (10,),...           0.692484   \n",
       "5   {'batch_size': 1, 'hidden_layer_sizes': (10,),...           0.715743   \n",
       "6   {'batch_size': 1, 'hidden_layer_sizes': (10,),...           0.714096   \n",
       "7   {'batch_size': 1, 'hidden_layer_sizes': (10,),...           0.713838   \n",
       "8   {'batch_size': 1, 'hidden_layer_sizes': (5, 5)...           0.430921   \n",
       "9   {'batch_size': 1, 'hidden_layer_sizes': (5, 5)...           0.697229   \n",
       "10  {'batch_size': 1, 'hidden_layer_sizes': (5, 5)...           0.487694   \n",
       "11  {'batch_size': 1, 'hidden_layer_sizes': (5, 5)...           0.688709   \n",
       "12  {'batch_size': 1, 'hidden_layer_sizes': (5, 5)...           0.702700   \n",
       "13  {'batch_size': 1, 'hidden_layer_sizes': (5, 5)...           0.704089   \n",
       "14  {'batch_size': 1, 'hidden_layer_sizes': (5, 5)...           0.671646   \n",
       "15  {'batch_size': 1, 'hidden_layer_sizes': (5, 5)...           0.705663   \n",
       "16  {'batch_size': 1, 'hidden_layer_sizes': 15, 'l...           0.636080   \n",
       "17  {'batch_size': 1, 'hidden_layer_sizes': 15, 'l...           0.678973   \n",
       "18  {'batch_size': 1, 'hidden_layer_sizes': 15, 'l...           0.660680   \n",
       "19  {'batch_size': 1, 'hidden_layer_sizes': 15, 'l...           0.680915   \n",
       "20  {'batch_size': 1, 'hidden_layer_sizes': 15, 'l...           0.705085   \n",
       "21  {'batch_size': 1, 'hidden_layer_sizes': 15, 'l...           0.718362   \n",
       "22  {'batch_size': 1, 'hidden_layer_sizes': 15, 'l...           0.715768   \n",
       "23  {'batch_size': 1, 'hidden_layer_sizes': 15, 'l...           0.723402   \n",
       "24  {'batch_size': 100, 'hidden_layer_sizes': (10,...           0.718608   \n",
       "25  {'batch_size': 100, 'hidden_layer_sizes': (10,...           0.710396   \n",
       "26  {'batch_size': 100, 'hidden_layer_sizes': (10,...           0.714760   \n",
       "27  {'batch_size': 100, 'hidden_layer_sizes': (10,...           0.709412   \n",
       "28  {'batch_size': 100, 'hidden_layer_sizes': (10,...           0.714022   \n",
       "29  {'batch_size': 100, 'hidden_layer_sizes': (10,...           0.722001   \n",
       "30  {'batch_size': 100, 'hidden_layer_sizes': (10,...           0.716936   \n",
       "31  {'batch_size': 100, 'hidden_layer_sizes': (10,...           0.721399   \n",
       "32  {'batch_size': 100, 'hidden_layer_sizes': (5, ...           0.716309   \n",
       "33  {'batch_size': 100, 'hidden_layer_sizes': (5, ...           0.706105   \n",
       "34  {'batch_size': 100, 'hidden_layer_sizes': (5, ...           0.709166   \n",
       "35  {'batch_size': 100, 'hidden_layer_sizes': (5, ...           0.698323   \n",
       "36  {'batch_size': 100, 'hidden_layer_sizes': (5, ...           0.705749   \n",
       "37  {'batch_size': 100, 'hidden_layer_sizes': (5, ...           0.713014   \n",
       "38  {'batch_size': 100, 'hidden_layer_sizes': (5, ...           0.708748   \n",
       "39  {'batch_size': 100, 'hidden_layer_sizes': (5, ...           0.707285   \n",
       "40  {'batch_size': 100, 'hidden_layer_sizes': 15, ...           0.726587   \n",
       "41  {'batch_size': 100, 'hidden_layer_sizes': 15, ...           0.720735   \n",
       "42  {'batch_size': 100, 'hidden_layer_sizes': 15, ...           0.724742   \n",
       "43  {'batch_size': 100, 'hidden_layer_sizes': 15, ...           0.715055   \n",
       "44  {'batch_size': 100, 'hidden_layer_sizes': 15, ...           0.724841   \n",
       "45  {'batch_size': 100, 'hidden_layer_sizes': 15, ...           0.728283   \n",
       "46  {'batch_size': 100, 'hidden_layer_sizes': 15, ...           0.723157   \n",
       "47  {'batch_size': 100, 'hidden_layer_sizes': 15, ...           0.728504   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.575164           0.644845           0.660319   \n",
       "1            0.688095           0.688095           0.684132   \n",
       "2            0.620467           0.540348           0.680432   \n",
       "3            0.680337           0.689742           0.659864   \n",
       "4            0.691340           0.682722           0.712666   \n",
       "5            0.711514           0.720231           0.716994   \n",
       "6            0.707334           0.711293           0.711388   \n",
       "7            0.715215           0.713432           0.714179   \n",
       "8            0.426213           0.487682           0.487688   \n",
       "9            0.686214           0.686706           0.673830   \n",
       "10           0.487682           0.364621           0.453449   \n",
       "11           0.675850           0.663433           0.699389   \n",
       "12           0.695483           0.688205           0.696143   \n",
       "13           0.700278           0.711662           0.709445   \n",
       "14           0.696516           0.688341           0.704159   \n",
       "15           0.706265           0.702392           0.709372   \n",
       "16           0.603956           0.633252           0.653975   \n",
       "17           0.676612           0.680509           0.693844   \n",
       "18           0.614197           0.632920           0.629498   \n",
       "19           0.687173           0.679428           0.692160   \n",
       "20           0.712178           0.698102           0.725772   \n",
       "21           0.720907           0.723009           0.713023   \n",
       "22           0.716715           0.715522           0.721371   \n",
       "23           0.715522           0.716948           0.718949   \n",
       "24           0.721251           0.714612           0.718764   \n",
       "25           0.715731           0.713371           0.719317   \n",
       "26           0.715498           0.716223           0.721174   \n",
       "27           0.711723           0.707802           0.713207   \n",
       "28           0.712817           0.719456           0.716896   \n",
       "29           0.714010           0.714883           0.719195   \n",
       "30           0.718116           0.714280           0.716490   \n",
       "31           0.713223           0.712227           0.720448   \n",
       "32           0.706732           0.706326           0.714609   \n",
       "33           0.699491           0.714022           0.698860   \n",
       "34           0.708957           0.712904           0.714486   \n",
       "35           0.703364           0.706289           0.707036   \n",
       "36           0.712830           0.710432           0.716687   \n",
       "37           0.709043           0.702909           0.712519   \n",
       "38           0.710174           0.697106           0.712212   \n",
       "39           0.703966           0.715633           0.714289   \n",
       "40           0.725615           0.729574           0.726792   \n",
       "41           0.724411           0.719628           0.721629   \n",
       "42           0.724226           0.718596           0.722649   \n",
       "43           0.721657           0.717932           0.723325   \n",
       "44           0.722739           0.725800           0.723079   \n",
       "45           0.726599           0.729217           0.728710   \n",
       "46           0.727582           0.724792           0.725846   \n",
       "47           0.723845           0.726648           0.729153   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.577937         0.599760        0.045363               46  \n",
       "1            0.684685         0.687643        0.003239               37  \n",
       "2            0.674162         0.633069        0.050936               44  \n",
       "3            0.660048         0.674634        0.012367               42  \n",
       "4            0.711818         0.698206        0.011950               34  \n",
       "5            0.712433         0.715383        0.003159               18  \n",
       "6            0.667154         0.702253        0.017681               33  \n",
       "7            0.705167         0.712366        0.003648               20  \n",
       "8            0.487688         0.464038        0.029000               47  \n",
       "9            0.665753         0.681946        0.010977               40  \n",
       "10           0.487688         0.456227        0.047684               48  \n",
       "11           0.680567         0.681590        0.012093               41  \n",
       "12           0.687857         0.694078        0.005545               35  \n",
       "13           0.706249         0.706345        0.003995               28  \n",
       "14           0.698246         0.691781        0.011267               36  \n",
       "15           0.704651         0.705668        0.002273               29  \n",
       "16           0.661462         0.637745        0.019953               43  \n",
       "17           0.685866         0.683161        0.006147               39  \n",
       "18           0.627580         0.632975        0.015240               45  \n",
       "19           0.688349         0.685605        0.004756               38  \n",
       "20           0.712113         0.710650        0.009182               21  \n",
       "21           0.717867         0.718634        0.003360                9  \n",
       "22           0.708241         0.715523        0.004212               17  \n",
       "23           0.714129         0.717790        0.003228               10  \n",
       "24           0.714191         0.717485        0.002690               12  \n",
       "25           0.707405         0.713244        0.004130               19  \n",
       "26           0.714277         0.716386        0.002483               15  \n",
       "27           0.706101         0.709649        0.002570               25  \n",
       "28           0.715728         0.715784        0.002308               16  \n",
       "29           0.718518         0.717721        0.002931               11  \n",
       "30           0.716908         0.716546        0.001256               14  \n",
       "31           0.718334         0.717126        0.003741               13  \n",
       "32           0.705364         0.709868        0.004618               24  \n",
       "33           0.704196         0.704535        0.005481               31  \n",
       "34           0.706778         0.710458        0.002817               22  \n",
       "35           0.705856         0.704174        0.003174               32  \n",
       "36           0.700102         0.709160        0.005752               27  \n",
       "37           0.709064         0.709310        0.003609               26  \n",
       "38           0.697729         0.705194        0.006447               30  \n",
       "39           0.709728         0.710180        0.004332               23  \n",
       "40           0.722674         0.726248        0.002220                3  \n",
       "41           0.721137         0.721508        0.001594                7  \n",
       "42           0.722723         0.722587        0.002158                6  \n",
       "43           0.720891         0.719772        0.002935                8  \n",
       "44           0.718063         0.722904        0.002669                5  \n",
       "45           0.724592         0.727480        0.001691                1  \n",
       "46           0.718027         0.723881        0.003262                4  \n",
       "47           0.727063         0.727043        0.001842                2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 3/5; 1/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.645 total time=30.3min\n",
      "[CV 1/5; 6/48] START batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 1/5; 6/48] END batch_size=1, hidden_layer_sizes=(10,), learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.716 total time=52.9min\n",
      "[CV 3/5; 10/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 3/5; 10/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.687 total time=44.3min\n",
      "[CV 1/5; 15/48] START batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd\n",
      "[CV 1/5; 15/48] END batch_size=1, hidden_layer_sizes=(5, 5), learning_rate_init=0.001, max_iter=200, n_iter_no_change=10, solver=sgd;, score=0.672 total time=61.1min\n",
      "[CV 4/5; 18/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam\n",
      "[CV 4/5; 18/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.01, max_iter=150, n_iter_no_change=10, solver=adam;, score=0.694 total time=32.1min\n",
      "[CV 4/5; 21/48] START batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd\n",
      "[CV 4/5; 21/48] END batch_size=1, hidden_layer_sizes=15, learning_rate_init=0.001, max_iter=150, n_iter_no_change=10, solver=sgd;, score=0.726 total time=112.7min\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(gridSearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor configuração:\n",
      " {'batch_size': 100, 'hidden_layer_sizes': 15, 'learning_rate_init': 0.001, 'max_iter': 150, 'n_iter_no_change': 10, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print('Melhor configuração:\\n', gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFgIIIovv6Fu"
   },
   "source": [
    "## Empacotando a solução\n",
    "\n",
    "Suponha que você deve entregar este classificador ao órgão responsável por administrar o Roosevelt National Park. Para tanto, você deve fazer uma preparação do mesmo para utilização neste cenário. Uma vez que já identificou os melhores parâmetros e hiperparâmetros, o passo remanescente consiste em treinar o modelo com estes valores e todos os dados disponíveis, salvando o conjunto de pesos do modelo ao final para entrega ao cliente. Assim, finalize o projeto prático realizando tais passos.\n",
    "\n",
    "1. Consulte a documentação a seguir:\n",
    "https://scikit-learn.org/stable/modules/model_persistence.html  \n",
    "2. Treine o modelo com todos os dados  \n",
    "3. Salve o modelo em disco  \n",
    "4. Construa uma rotina que recupere o modelo em disco  \n",
    "5. Mostre que a rotina é funcional, fazendo previsões com todos os elementos do dataset e exibindo uma matriz de confusão das mesmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Et-g8OBxv6Fu"
   },
   "outputs": [],
   "source": [
    "from pickle import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Treinando o modelo com todos os dados\n",
    "\n",
    "2.1 Separando os dados em atributos preditores e atributo alvo, rescpectivamente X_train_std e y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forest_cover = df_forest_cover.sample(n = len(df_forest_cover))\n",
    "\n",
    "y = df_forest_cover['Cover_Type']\n",
    "X = df_forest_cover.drop('Cover_Type', axis=1)\n",
    "\n",
    "X_train_std = (X - np.mean(X))/np.std(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train_std, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Salve o modelo em disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(best_model, open(\"model.pkl\", \"wb\"))\n",
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Construa uma rotina que recupere o modelo em disco\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = load(open(\"model.pkl\", \"rb\"))\n",
    "final_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Mostre que a rotina é funcional, fazendo previsões com todos os elementos do dataset e exibindo uma matriz de confusão das mesmas\n",
    "\n",
    "5.1 Fazendo previsões com todos os elementos do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_model.predict(X_train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, y_pred, labels=final_model.classes_)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=final_model.classes_)\n",
    "disp.plot(cmap = \"Blues\")\n",
    "plt.title(\"Matriz de confusão\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "PP2.2.3 - Validação Cruzada e Busca em Grade.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
